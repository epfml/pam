{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ac73115-af09-45ef-8588-823c2eebebd5",
   "metadata": {},
   "source": [
    "The goal of this notebook is to implement other ops, in particular:\n",
    "* Division\n",
    "* Exponents and logarithms (arbitrary base)\n",
    "* Normalization\n",
    "* Square root\n",
    "* Softmax\n",
    "* Softmax cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df48542-5d84-44de-ad48-4bf7acc38572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d0a766-7ea0-42c7-95f4-f3543b990e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313690b-0019-4511-b8fa-61934c392b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pam\n",
    "import cuda_bindings\n",
    "import native"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546b5df-b729-4c7e-9838-b22570d53b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primitives along with their real equivalents\n",
    "c = 1.7\n",
    "offset = 1.0\n",
    "N_tensor = 32\n",
    "\n",
    "functions = [\n",
    "    [f'{c}*x',\n",
    "     lambda x, **kwargs: cuda_bindings.pam(x, torch.full_like(x, c), **kwargs),\n",
    "     lambda x, **kwargs: native.pam(x, torch.full_like(x, c), **kwargs),\n",
    "     lambda x: c*x,\n",
    "     -3, 3],\n",
    "    [f'x^2',\n",
    "     lambda x, **kwargs: cuda_bindings.pam(x, x, **kwargs),\n",
    "     lambda x, **kwargs: native.pam(x, x, **kwargs),\n",
    "     lambda x: x*x,\n",
    "     -3, 3],\n",
    "    [f'{c}/x',\n",
    "     lambda x, **kwargs: cuda_bindings.pad(torch.full_like(x, c), x, **kwargs),\n",
    "     lambda x, **kwargs: native.pad(torch.full_like(x, c), x, **kwargs),\n",
    "     lambda x: c/x,\n",
    "     1/3, 3],\n",
    "    [f'x/{c}',\n",
    "     lambda x, **kwargs: cuda_bindings.pad(x, torch.full_like(x, c), **kwargs),\n",
    "     lambda x, **kwargs: native.pad(x, torch.full_like(x, c), **kwargs),\n",
    "     lambda x: x/c,\n",
    "     1/3, 3],\n",
    "    ['exp2', cuda_bindings.pa_exp2, native.pa_exp2, torch.exp2, -3, 5],\n",
    "    ['exp', cuda_bindings.pa_exp, native.pa_exp, torch.exp, -3, 5],\n",
    "    ['log2', cuda_bindings.pa_log2, native.pa_log2, torch.log2, 0.5, 5],\n",
    "    ['ln', cuda_bindings.pa_log, native.pa_log, torch.log, 0.5, 5],\n",
    "    ['sqrt',\n",
    "     lambda x, **kwargs: pam.pow(x, 0.5, use_kernel=True, **kwargs),\n",
    "     lambda x, **kwargs: pam.pow(x, 0.5, use_kernel=False, **kwargs),\n",
    "     lambda x: x**0.5,\n",
    "     0.1, 10],\n",
    "    ['softmax',\n",
    "     lambda x, **kwargs: pam.softmax(x, use_kernel=True, **kwargs),\n",
    "     lambda x, **kwargs: pam.softmax(x, use_kernel=False, **kwargs),\n",
    "     lambda x: torch.nn.functional.softmax(x, dim=0),\n",
    "     -2, 2],\n",
    "    ['log_softmax',\n",
    "     lambda x, **kwargs: pam.log_softmax(x, use_kernel=True, **kwargs),\n",
    "     lambda x, **kwargs: pam.log_softmax(x, use_kernel=False, **kwargs),\n",
    "     lambda x: torch.nn.functional.log_softmax(x, dim=0),\n",
    "     -2, 2],\n",
    "    ['layer_norm',\n",
    "     lambda x, **kwargs: pam.layer_norm(x, N_tensor, use_kernel=True, **kwargs),\n",
    "     lambda x, **kwargs: pam.layer_norm(x, N_tensor, use_kernel=False, **kwargs),\n",
    "     lambda x: torch.nn.functional.layer_norm(x, (N_tensor,)),\n",
    "     -5, 5],\n",
    "]\n",
    "\n",
    "for f in functions:\n",
    "    name, cuda_f, native_f, real_f, min_x, max_x = f\n",
    "    if name in ['softmax', 'log_softmax', 'layer_norm']:\n",
    "        X = torch.rand(N_tensor, device='cuda') * (max_x - min_x) + min_x\n",
    "        dY = torch.randn_like(X)\n",
    "        X_axis = torch.arange(N_tensor).numpy()\n",
    "    else:\n",
    "        N = 1000\n",
    "        X = torch.linspace(min_x, max_x, N, device='cuda')\n",
    "        dY = torch.full_like(X, 1.2)\n",
    "        X_axis = X.numpy(force=True)\n",
    "\n",
    "    X1 = torch.clone(X).requires_grad_(True)\n",
    "    Y1 = cuda_f(X1, offset=offset)\n",
    "    Y1.backward(dY)\n",
    "    X1a = torch.clone(X).requires_grad_(True)\n",
    "    Y1a = cuda_f(X1a, approx_bwd=True, offset=offset)\n",
    "    Y1a.backward(dY)\n",
    "\n",
    "\n",
    "    X2 = torch.clone(X).requires_grad_(True)\n",
    "    Y2 = native_f(X2, offset=offset)\n",
    "    Y2.backward(dY)\n",
    "    X2a = torch.clone(X).requires_grad_(True)\n",
    "    Y2a = native_f(X2a, approx_bwd=True, offset=offset)\n",
    "    Y2a.backward(dY)\n",
    "    \n",
    "    X3 = torch.clone(X).requires_grad_(True)\n",
    "    Y3 = real_f(X3)\n",
    "    Y3.backward(dY)\n",
    "    \n",
    "    plt.figure(figsize=(9, 3))\n",
    "    plt.subplot(131)\n",
    "    plt.plot(X_axis, Y1.numpy(force=True), 'k', label='cuda',)\n",
    "    plt.plot(X_axis, Y2.numpy(force=True), 'r:', label='native')\n",
    "    plt.plot(X_axis, Y3.numpy(force=True), 'b--', label='real')\n",
    "    plt.ylabel(name)\n",
    "    # plt.yscale('log')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.plot(X_axis, X1.grad.numpy(force=True), 'k', label='cuda')\n",
    "    plt.plot(X_axis, X2.grad.numpy(force=True), 'r:', label='native')\n",
    "    plt.plot(X_axis, X3.grad.numpy(force=True), 'b--', label='real')\n",
    "    plt.ylabel('d/dx ' + name)\n",
    "    # plt.yscale('log')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.plot(X_axis, X1a.grad.numpy(force=True), 'k', label='cuda')\n",
    "    plt.plot(X_axis, X2a.grad.numpy(force=True), 'r:', label='native')\n",
    "    plt.plot(X_axis, X3.grad.numpy(force=True), 'b--', label='real')\n",
    "    plt.ylabel('approx d/dx ' + name)\n",
    "    # plt.yscale('log')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17327a-f4d3-45e4-acbe-12499072f286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
